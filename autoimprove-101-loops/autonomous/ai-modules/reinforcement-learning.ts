#!/usr/bin/env bun
/**
 * Reinforcement Learning Agent - Learning through environment interaction
 *
 * Capabilities:
 * - Q-Learning algorithm
 * - Policy gradient methods
 * - Experience replay buffer
 * - Exploration vs exploitation
 */

interface State {
  id: string
  features: number[]
}

interface Action {
  id: string
  name: string
  params?: any
}

interface Experience {
  state: State
  action: Action
  reward: number
  nextState: State
  done: boolean
}

interface Policy {
  stateActionValues: Map<string, Map<string, number>>
  explorationRate: number
}

class ReinforcementLearningAgent {
  private qTable: Map<string, Map<string, number>> = new Map()
  private experienceBuffer: Experience[] = []
  private maxBufferSize = 10000
  private explorationRate = 0.3
  private learningRate = 0.1
  private discountFactor = 0.95

  constructor() {
    console.log('üéÆ Initializing Reinforcement Learning Agent...\n')
    console.log('‚úÖ RL Agent ready')
    console.log('   Capabilities: q-learning, policy gradient, experience replay')
  }

  /**
   * EXPLORE ENVIRONMENT - Gather experiences through interaction
   */
  async exploreEnvironment(episodes: number = 100): Promise<Experience[]> {
    console.log(`\nüîç Exploring environment (${episodes} episodes)`)

    const experiences: Experience[] = []

    for (let episode = 0; episode < episodes; episode++) {
      const state = this.getInitialState()

      let step = 0
      let totalReward = 0
      let done = false

      while (!done && step < 50) {
        // Select action (epsilon-greedy)
        const action = this.selectAction(state)

        // Take action and observe result
        const { nextState, reward, done: episodeDone } = await this.takeAction(state, action)

        const experience: Experience = {
          state,
          action,
          reward,
          nextState,
          done: episodeDone
        }

        experiences.push(experience)
        this.addToBuffer(experience)

        // Learn from experience
        this.updateQTable(experience)

        totalReward += reward
        state.id = nextState.id
        state.features = nextState.features
        done = episodeDone
        step++
      }

      if (episode % 10 === 0) {
        console.log(`   Episode ${episode}: reward=${totalReward.toFixed(1)}, steps=${step}`)
      }
    }

    console.log(`   ‚úÖ Exploration complete`)
    console.log(`      Experiences gathered: ${experiences.length}`)

    return experiences
  }

  private getInitialState(): State {
    return {
      id: crypto.randomUUID(),
      features: Array.from({ length: 10 }, () => Math.random())
    }
  }

  private selectAction(state: State): Action {
    // Epsilon-greedy action selection
    if (Math.random() < this.explorationRate) {
      // Explore: random action
      return {
        id: crypto.randomUUID(),
        name: ['up', 'down', 'left', 'right'][Math.floor(Math.random() * 4)]
      }
    } else {
      // Exploit: best action from Q-table
      const stateKey = this.getStateKey(state)
      const actions = this.qTable.get(stateKey)

      if (!actions || actions.size === 0) {
        return {
          id: crypto.randomUUID(),
          name: ['up', 'down', 'left', 'right'][Math.floor(Math.random() * 4)]
        }
      }

      let bestAction = 'up'
      let bestValue = -Infinity

      for (const [action, value] of actions) {
        if (value > bestValue) {
          bestValue = value
          bestAction = action
        }
      }

      return { id: crypto.randomUUID(), name: bestAction }
    }
  }

  private async takeAction(state: State, action: Action): Promise<{
    nextState: State
    reward: number
    done: boolean
  }> {
    // Simulate environment transition
    await this.sleep(10)

    const nextState: State = {
      id: crypto.randomUUID(),
      features: state.features.map(f => f + (Math.random() - 0.5) * 0.1)
    }

    // Simulate reward (higher if certain features are high)
    const reward = nextState.features.reduce((sum, f) => sum + f, 0) * 10 - 5

    // Episode done with 5% probability
    const done = Math.random() < 0.05

    return { nextState, reward, done }
  }

  private getStateKey(state: State): string {
    // Discretize state for Q-table lookup
    const bucket = state.features.map(f => Math.floor(f * 10)).join('-')
    return bucket
  }

  private updateQTable(experience: Experience): void {
    const stateKey = this.getStateKey(experience.state)
    const actionKey = experience.action.name

    if (!this.qTable.has(stateKey)) {
      this.qTable.set(stateKey, new Map())
    }

    const currentQ = this.qTable.get(stateKey)!.get(actionKey) || 0

    // Find max Q for next state
    const nextStateKey = this.getStateKey(experience.nextState)
    const nextActions = this.qTable.get(nextStateKey)
    const maxNextQ = nextActions ? Math.max(0, ...nextActions.values()) : 0

    // Q-learning update
    const newQ = currentQ + this.learningRate * (
      experience.reward +
      this.discountFactor * maxNextQ * (experience.done ? 0 : 1) -
      currentQ
    )

    this.qTable.get(stateKey)!.set(actionKey, newQ)
  }

  private addToBuffer(experience: Experience): void {
    this.experienceBuffer.push(experience)

    if (this.experienceBuffer.length > this.maxBufferSize) {
      this.experienceBuffer.shift()
    }
  }

  /**
   * UPDATE POLICY - Improve policy based on experiences
   */
  updatePolicy(experiences: Experience[]): Policy {
    console.log(`\nüìà Updating policy from ${experiences.length} experiences`)

    // Decay exploration rate
    this.explorationRate = Math.max(0.01, this.explorationRate * 0.995)

    const policy: Policy = {
      stateActionValues: new Map(this.qTable),
      explorationRate: this.explorationRate
    }

    console.log(`   ‚úÖ Policy updated`)
    console.log(`      Exploration rate: ${(this.explorationRate * 100).toFixed(1)}%`)
    console.log(`      States explored: ${this.qTable.size}`)

    return policy
  }

  /**
   * OPTIMIZE REWARD - Fine-tune for maximum reward
   */
  async optimizeReward(episodes: number = 50): Promise<{
    averageReward: number
    bestReward: number
    convergenceEpisode: number
  }> {
    console.log(`\nüéØ Optimizing for reward (${episodes} episodes)`)

    let bestReward = -Infinity
    let totalReward = 0
    let convergedAt = 0
    let lastImprovement = 0

    for (let episode = 0; episode < episodes; episode++) {
      const state = this.getInitialState()
      let episodeReward = 0
      let done = false
      let steps = 0

      while (!done && steps < 50) {
        const action = this.selectAction(state)
        const { nextState, reward, done: episodeDone } = await this.takeAction(state, action)

        episodeReward += reward
        state.id = nextState.id
        state.features = nextState.features
        done = episodeDone
        steps++
      }

      totalReward += episodeReward

      if (episodeReward > bestReward) {
        bestReward = episodeReward
        lastImprovement = episode
      }

      // Check for convergence (no improvement for 10 episodes)
      if (episode - lastImprovement > 10 && convergedAt === 0) {
        convergedAt = episode
      }

      if (episode % 10 === 0) {
        console.log(`   Episode ${episode}: avg=${(totalReward / (episode + 1)).toFixed(1)}, best=${bestReward.toFixed(1)}`)
      }
    }

    return {
      averageReward: totalReward / episodes,
      bestReward,
      convergenceEpisode: convergedAt
    }
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }

  getMetrics() {
    return {
      statesExplored: this.qTable.size,
      experiencesCollected: this.experienceBuffer.length,
      explorationRate: this.explorationRate
    }
  }
}

export { ReinforcementLearningAgent, State, Action, Experience, Policy }

if (import.meta.main) {
  console.log('üß™ Reinforcement Learning Agent Test\n')

  const agent = new ReinforcementLearningAgent()

  // Explore
  await agent.exploreEnvironment(50)

  // Update policy
  agent.updatePolicy([])

  // Optimize
  const result = await agent.optimizeReward(30)

  console.log(`\nResults:`)
  console.log(`  Average reward: ${result.averageReward.toFixed(2)}`)
  console.log(`  Best reward: ${result.bestReward.toFixed(2)}`)
  console.log(`  Converged at: ${result.convergenceEpisode}`)

  console.log('\n‚úÖ Reinforcement Learning Agent loaded')
}
